{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1b1e67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torch.nn as nn \n",
    "from torch.autograd import Variable\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import math \n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PeptideDataset import *\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6092228",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#assuming r=1\n",
    "def cartesian_to_spherical(x, y, z):\n",
    "    theta = math.acos(z / 1)  \n",
    "    phi = math.atan2(y, x)\n",
    "    if phi < 0:\n",
    "        phi += 2*np.pi\n",
    "    return [theta, phi]\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def fibonacci_sphere(n):\n",
    "\n",
    "    points = []\n",
    "    phi = math.pi * (math.sqrt(5.) - 1.)  # golden angle in radians\n",
    "\n",
    "    for i in range(n):\n",
    "        y = 1 - (i / float(n - 1)) * 2  # y goes from 1 to -1\n",
    "        radius = math.sqrt(1 - y * y)  # radius at y\n",
    "\n",
    "        theta = phi * i  # golden angle increment\n",
    "\n",
    "        x = math.cos(theta) * radius\n",
    "        z = math.sin(theta) * radius\n",
    "        points.append((x, y, z))\n",
    "        sph_points = [cartesian_to_spherical(x,y,z) for x,y,z in points]\n",
    "    \n",
    "    return sph_points\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9545599e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dtype = torch.cuda.DoubleTensor if torch.cuda.is_available() else torch.DoubleTensor\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "class VariationalQuantumClassifierInterface:\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_of_input,\n",
    "            num_of_output,\n",
    "            num_of_wires,\n",
    "            num_of_layers,\n",
    "            var_Q_circuit,\n",
    "            var_Q_bias,\n",
    "            qdevice):\n",
    "\n",
    "        self.var_Q_circuit = var_Q_circuit\n",
    "        self.var_Q_bias = var_Q_bias\n",
    "        self.num_of_input = num_of_input\n",
    "        self.num_of_output = num_of_output\n",
    "        self.num_of_wires = num_of_wires\n",
    "        self.num_of_layers = num_of_layers\n",
    "\n",
    "        self.qdevice = qdevice\n",
    "\n",
    "        self.dev = qml.device(self.qdevice, wires = num_of_wires)\n",
    "\n",
    "\n",
    "    def set_params(self, var_Q_circuit, var_Q_bias):\n",
    "        self.var_Q_circuit = var_Q_circuit\n",
    "        self.var_Q_bias = var_Q_bias\n",
    "\n",
    "    def init_params(self):\n",
    "        self.var_Q_circuit = Variable(torch.tensor(0.01 * np.random.randn(self.num_of_layers, self.num_of_wires, 3), device=device).type(dtype), requires_grad=True)\n",
    "        return self.var_Q_circuit\n",
    "\n",
    "    def _statepreparation(self, angles):\n",
    "\n",
    "        \"\"\"Encoding block of circuit given angles\n",
    "\n",
    "        Args:\n",
    "            a: feature vector of rad and rad_square => np.array([rad_X_0, rad_X_1, rad_square_X_0, rad_square_X_1])\n",
    "        \"\"\"\n",
    "        # num_of_input determines the number of rotation needed.\n",
    "\n",
    "        for i in range(self.num_of_input):\n",
    "            qml.RY(angles[i,0], wires=i)\n",
    "            qml.RZ(angles[i,1], wires=i)\n",
    "\n",
    "    def _layer(self, W):\n",
    "        \"\"\" Single layer of the variational classifier.\n",
    "\n",
    "        Args:\n",
    "            W (array[float]): 2-d array of variables for one layer\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Entanglement Layer\n",
    "\n",
    "        for i in range(self.num_of_wires):\n",
    "            qml.CNOT(wires=[i, (i + 1) % self.num_of_wires])\n",
    "\n",
    "        # Rotation Layer\n",
    "        for j in range(self.num_of_wires):\n",
    "            qml.Rot(W[j, 0], W[j, 1], W[j, 2], wires=j)\n",
    "\n",
    "    def circuit(self, angles):\n",
    "\n",
    "        @qml.qnode(self.dev, interface='torch', diff_method = \"parameter-shift\")\n",
    "        def _circuit(var_Q_circuit, angles):\n",
    "            \"\"\"The circuit of the variational classifier.\"\"\"\n",
    "            self._statepreparation(angles)\n",
    "            weights = var_Q_circuit\n",
    "\n",
    "            for W in weights:\n",
    "                self._layer(W)\n",
    "\n",
    "\n",
    "            k = self.num_of_input-1\n",
    "            return [qml.expval(qml.PauliZ(k))]\n",
    "\n",
    "        return _circuit(self.var_Q_circuit, angles)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, angles):\n",
    "        result = ((self.circuit(angles)))\n",
    "        return torch.tensor(result, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70245f37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vqc = VariationalQuantumClassifierInterface(\n",
    "            num_of_input =6,\n",
    "            num_of_output =1,\n",
    "            num_of_wires=6,\n",
    "            num_of_layers=2,\n",
    "            var_Q_circuit=None,\n",
    "            var_Q_bias = None,\n",
    "            qdevice = \"default.qubit\")\n",
    "           \n",
    "fib_angles = fibonacci_sphere(5)\n",
    "         \n",
    "\n",
    "class VQCTorch(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.q_params = nn.Parameter(0.01 * torch.randn(2, 6, 3))\n",
    "    def get_angles(self, in_x):\n",
    "        in_x_int = [int(item) for item in in_x.tolist()]\n",
    "        angles = []\n",
    "        for item in in_x_int:\n",
    "            theta = fib_angles[item][0]\n",
    "            phi = fib_angles[item][1]\n",
    "            angles.append([theta, phi])\n",
    "\n",
    "        return torch.tensor(angles, requires_grad=True)\n",
    "\n",
    "\n",
    "    def forward(self, batch_item):\n",
    "        vqc.var_Q_circuit = self.q_params\n",
    "        output_batch = []\n",
    "\n",
    "        for single_item in batch_item:\n",
    "            angles = self.get_angles(single_item)\n",
    "\n",
    "            q_out_elem = vqc.forward(angles)\n",
    "            \n",
    "            output_batch.append(q_out_elem)\n",
    "\n",
    "        outputs = torch.stack(output_batch).view(len(batch_item), 1) \n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932c3723",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {'batch_size' : 4, 'lr': 0.01, 'epochs': 50}\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483e9cc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "dataset = ToyPeptideDataset()\n",
    "\n",
    "# train_size = int(0.8 * len(dataset))\n",
    "# test_size = (len(dataset) - train_size) // 2\n",
    "# val_size = len(dataset) - train_size - test_size\n",
    "\n",
    "train_size = int(0.16 * len(dataset))\n",
    "test_size = int(0.02 * len(dataset))\n",
    "val_size = int(0.02 * len(dataset))\n",
    "not_used = len(dataset) - train_size - test_size - val_size\n",
    "train_dataset, test_dataset, val_dataset, not_used_dataset = random_split(dataset, [train_size, test_size, val_size, not_used])\n",
    "\n",
    "print(f\"Dataset: {len(dataset)}\")\n",
    "print(f\"Train: {len(train_dataset)}\")\n",
    "print(f\"Test: {len(test_dataset)}\")\n",
    "print(f\"Validation: {len(val_dataset)}\")\n",
    "print(f\"Not_Used: {len(not_used_dataset)}\")\n",
    "\n",
    "batch_size = params['batch_size']\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "train_iter = iter(train_loader)\n",
    "train_data = next(train_iter)\n",
    "x_train, y_train = train_data\n",
    "\n",
    "test_iter = iter(test_loader)\n",
    "test_data = next(test_iter)\n",
    "x_test, y_test = test_data\n",
    "\n",
    "val_iter = iter(val_loader)\n",
    "val_data = next(val_iter)\n",
    "x_val, y_val = val_data\n",
    "\n",
    "\n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1b2615-fae5-4298-85d3-93af45c64d9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def saving_plotting(params, tr_list, val_list):\n",
    "    exp_name = datetime.now().strftime(\"%m_%d_%H_%M_%S\")\n",
    "\n",
    "    directory = f\"Exp:_{exp_name}\"\n",
    "    parent_dir = '/global/u2/r/rr637/VQC_Peptides/Results'\n",
    "    path = os.path.join(parent_dir, directory)\n",
    "    os.mkdir(path)\n",
    "    path_plots = path + '/Plots'\n",
    "    os.mkdir(path_plots)\n",
    "    path_models = path + '/Models'\n",
    "    os.mkdir(path_models)    \n",
    "    title = 'Train and Validation Loss'\n",
    "    plot_loss(tr_list, val_list, exp_name, title)\n",
    "    \n",
    "    with open(path + \"/train_loss.csv\", \"w\", newline=\"\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(tr_list)\n",
    "\n",
    "    with open(path + \"/val_loss.csv\", \"w\", newline=\"\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(val_list)\n",
    "    with open(path + \"/params.csv\", \"w\", newline=\"\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        for key, value in params.items():\n",
    "            writer.writerow([key, value])\n",
    "    return \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_loss(tr_l, vl_l,exp_name,title):\n",
    "    plt.plot(tr_l,label = \"train loss\")\n",
    "    plt.plot(vl_l,label = \"val loss\")\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"Results/Exp:_{exp_name}/Plots/loss_plot.png\")\n",
    "    plt.show()             \n",
    "             \n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f6543e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#Train and Validation Loop\n",
    "def train_model(model, optimizer, train_loader, val_loader, params):\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    batch_size = params['batch_size']\n",
    "    num_epochs = params['epochs']\n",
    "    train_samples = len(train_dataset)\n",
    "    val_samples = len(val_dataset)\n",
    "    n_tr_iterations = math.ceil(train_samples/batch_size)\n",
    "    n_val_iterations = math.ceil(val_samples/batch_size)\n",
    "\n",
    "    train_loss_epoch = []\n",
    "    val_loss_epoch = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        print(f\"EPOCH: {epoch}\")\n",
    "        train_loss = 0\n",
    "        for p in model.parameters():\n",
    "            if p.requires_grad:\n",
    "                print(f\"Parameter name: {p.name}, Value: {p.data}\")\n",
    "\n",
    "        for i, (data, target) in enumerate(train_loader):\n",
    "            \n",
    "            \n",
    "            if i == 0:\n",
    "                print(f'Inputs {data.shape} | Labels {target.shape}')\n",
    "           \n",
    "            data, target = data.double().to(device), target.double().to(device)\n",
    "            y_predicted = model(data).double().to(device)\n",
    "            loss = criterion(y_predicted, target)\n",
    "            # print(f'Data: {data}')\n",
    "            # print(f'Target: {target}')\n",
    "            # print(f'Y_predicted: {y_predicted}')\n",
    "            # print(loss)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "\n",
    "            \n",
    "            if (i+1) % 1000 == 0:\n",
    "                print(f'Epoch: {epoch+1}/{num_epochs}, Step {i+1}/{n_tr_iterations}|train_loss = {loss.item():.4f}')\n",
    "        avg_tr_loss = train_loss/n_tr_iterations\n",
    "        print(f\"Avg_Train_Loss: {avg_tr_loss}\")\n",
    "        train_loss_epoch.append(avg_tr_loss)\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        for i, (data, target) in enumerate(val_loader):\n",
    "           \n",
    "            data, target = data.to(device), target.to(device)\n",
    "            y_predicted = model(data).to(device)\n",
    "            vloss = criterion(y_predicted, target)\n",
    "            val_loss += vloss.item()\n",
    "            if (i+1) % 500 == 0:\n",
    "                print(f'Epoch: {epoch+1}/{num_epochs}, Step {i+1}/{n_val_iterations}|val_loss = {vloss.item():.4f}')\n",
    "        avg_val_loss = train_loss/n_val_iterations\n",
    "        print(f\"Avg_Val_Loss: {avg_val_loss}\")\n",
    "        val_loss_epoch.append(avg_val_loss)\n",
    "    return train_loss_epoch,val_loss_epoch\n",
    "        \n",
    "    \n",
    "\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492be67f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = VQCTorch().double().to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=params['lr']) \n",
    "train_loss, val_loss = train_model(model, optimizer, train_loader, val_loader, params)\n",
    "saving_plotting(params, train_loss, val_loss)\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cbaff7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e41dfdd-1101-4006-967c-1fb2a2001be0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-1.13.1",
   "language": "python",
   "name": "pytorch-1.13.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
