{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD:VQC_main.ipynb
   "execution_count": null,
   "id": "3b1b1e67",
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 1,
   "id": "3b1b1e67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sympy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpennylane\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m numpy \u001b[38;5;28;01mas\u001b[39;00m np\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m \n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msympy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader, random_split\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sympy'"
     ]
    }
   ],
>>>>>>> df30bbe8cae2c3ac9663ae2c79f0323cc8a4adb9:VQC_first_draft.ipynb
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch.autograd import Variable\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import math \n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PeptideDataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6092228",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assuming r=1\n",
    "def cartesian_to_spherical(x, y, z):\n",
    "    theta = math.acos(z / 1)  \n",
    "    phi = math.atan2(y, x)\n",
    "    if phi < 0:\n",
    "        phi += 2*np.pi\n",
    "    return [theta, phi]\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def fibonacci_sphere(n):\n",
    "\n",
    "    points = []\n",
    "    phi = math.pi * (math.sqrt(5.) - 1.)  # golden angle in radians\n",
    "\n",
    "    for i in range(n):\n",
    "        y = 1 - (i / float(n - 1)) * 2  # y goes from 1 to -1\n",
    "        radius = math.sqrt(1 - y * y)  # radius at y\n",
    "\n",
    "        theta = phi * i  # golden angle increment\n",
    "\n",
    "        x = math.cos(theta) * radius\n",
    "        z = math.sin(theta) * radius\n",
    "        points.append((x, y, z))\n",
    "        sph_points = [cartesian_to_spherical(x,y,z) for x,y,z in points]\n",
    "    \n",
    "    return sph_points\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9545599e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.cuda.DoubleTensor if torch.cuda.is_available() else torch.DoubleTensor\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "class VariationalQuantumClassifierInterface:\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_of_input,\n",
    "            num_of_output,\n",
    "            num_of_wires,\n",
    "            num_of_layers,\n",
    "            var_Q_circuit,\n",
    "            var_Q_bias,\n",
    "            qdevice):\n",
    "\n",
    "        self.var_Q_circuit = var_Q_circuit\n",
    "        self.var_Q_bias = var_Q_bias\n",
    "        self.num_of_input = num_of_input\n",
    "        self.num_of_output = num_of_output\n",
    "        self.num_of_wires = num_of_wires\n",
    "        self.num_of_layers = num_of_layers\n",
    "\n",
    "        self.qdevice = qdevice\n",
    "\n",
    "        self.dev = qml.device(self.qdevice, wires = num_of_wires)\n",
    "\n",
    "\n",
    "    def set_params(self, var_Q_circuit, var_Q_bias):\n",
    "        self.var_Q_circuit = var_Q_circuit\n",
    "        self.var_Q_bias = var_Q_bias\n",
    "\n",
    "    def init_params(self):\n",
    "        self.var_Q_circuit = Variable(torch.tensor(0.01 * np.random.randn(self.num_of_layers, self.num_of_wires, 3), device=device).type(dtype), requires_grad=True)\n",
    "        return self.var_Q_circuit\n",
    "\n",
    "    def _statepreparation(self, angles):\n",
    "\n",
    "        \"\"\"Encoding block of circuit given angles\n",
    "\n",
    "        Args:\n",
    "            a: feature vector of rad and rad_square => np.array([rad_X_0, rad_X_1, rad_square_X_0, rad_square_X_1])\n",
    "        \"\"\"\n",
    "        # num_of_input determines the number of rotation needed.\n",
    "\n",
    "        for i in range(self.num_of_input):\n",
    "            qml.RY(angles[i,0], wires=i)\n",
    "            qml.RZ(angles[i,1], wires=i)\n",
    "\n",
    "    def _layer(self, W):\n",
    "        \"\"\" Single layer of the variational classifier.\n",
    "\n",
    "        Args:\n",
    "            W (array[float]): 2-d array of variables for one layer\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Entanglement Layer\n",
    "\n",
    "        for i in range(self.num_of_wires):\n",
    "            qml.CNOT(wires=[i, (i + 1) % self.num_of_wires])\n",
    "\n",
    "        # Rotation Layer\n",
    "        for j in range(self.num_of_wires):\n",
    "            qml.Rot(W[j, 0], W[j, 1], W[j, 2], wires=j)\n",
    "\n",
    "    def circuit(self, angles):\n",
    "\n",
    "        @qml.qnode(self.dev, interface='torch', diff_method = \"parameter-shift\")\n",
    "        def _circuit(var_Q_circuit, angles):\n",
    "            \"\"\"The circuit of the variational classifier.\"\"\"\n",
    "            self._statepreparation(angles)\n",
    "            weights = var_Q_circuit\n",
    "\n",
    "            for W in weights:\n",
    "                self._layer(W)\n",
    "\n",
    "\n",
    "            k = self.num_of_input-1\n",
    "            return [qml.expval(qml.PauliZ(k))]\n",
    "\n",
    "        return _circuit(self.var_Q_circuit, angles)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, angles):\n",
    "        result = ((self.circuit(angles).item()))\n",
    "        return torch.tensor(result, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70245f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "vqc = VariationalQuantumClassifierInterface(\n",
    "            num_of_input =12,\n",
    "            num_of_output =1,\n",
    "            num_of_wires=12,\n",
    "            num_of_layers=2,\n",
    "            var_Q_circuit=None,\n",
    "            var_Q_bias = None,\n",
    "            qdevice = \"default.qubit\")\n",
    "           \n",
    "fib_angles = fibonacci_sphere(18)\n",
    "         \n",
    "\n",
    "class VQCTorch(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.q_params = nn.Parameter(0.01 * torch.randn(2, 12, 3))\n",
    "    def get_angles(self, in_x):\n",
    "        in_x_int = [int(item) for item in in_x.tolist()]\n",
    "        angles = []\n",
    "        for item in in_x_int:\n",
    "            theta = fib_angles[item][0]\n",
    "            phi = fib_angles[item][1]\n",
    "            angles.append([theta, phi])\n",
    "\n",
    "        return torch.tensor(angles, requires_grad=True)\n",
    "\n",
    "\n",
    "    def forward(self, batch_item):\n",
    "        vqc.var_Q_circuit = self.q_params\n",
    "        output_batch = []\n",
    "\n",
    "        for single_item in batch_item:\n",
    "            angles = self.get_angles(single_item)\n",
    "\n",
    "            q_out_elem = vqc.forward(angles)\n",
    "            \n",
    "            output_batch.append(q_out_elem)\n",
    "\n",
    "        outputs = torch.stack(output_batch).view(len(batch_item), 1) \n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932c3723",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size' : 4, 'lr': 0.01, 'epochs': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483e9cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "dataset = PeptideDataset()\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size  = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "print(f\"Dataset: {len(dataset)}\")\n",
    "print(f\"(Train,Test): {train_size,test_size}\")\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size = params['batch_size'], shuffle = True, num_workers = 2)\n",
    "train_iter = iter(train_loader)\n",
    "train_data = next(train_iter)\n",
    "x_train, y_train = train_data\n",
    "\n",
    "test_loader = DataLoader(dataset = train_dataset, batch_size = params['batch_size'], shuffle = True, num_workers = 2)\n",
    "test_iter = iter(test_loader)\n",
    "test_data = next(test_iter)\n",
    "x_test, y_test = test_data\n",
    "\n",
    "\n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f6543e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VQCTorch()\n",
    "\n",
    "lr = params['lr']\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)  \n",
    "\n",
    "batch_size = params['batch_size']\n",
    "num_epochs = params['epochs']\n",
    "total_samples = len(train_dataset)\n",
    "n_iterations = math.ceil(total_samples/batch_size)\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"EPOCH: {epoch}\")\n",
    "    for i, (data, target) in enumerate(train_loader):\n",
    "        if i == 0:\n",
    "            print(f'Inputs {data.shape} | Labels {target.shape}')\n",
    "        y_predicted = model(data)\n",
    "        loss = criterion(y_predicted, target)\n",
    "    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #\n",
    "        if (i+1) % 5 == 0:\n",
    "            print(f'Epoch: {epoch+1}/{num_epochs}, Step {i+1}/{n_iterations}|loss = {loss.item():.4f}')\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492be67f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-1.13.1",
   "language": "python",
   "name": "pytorch-1.13.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD:VQC_main.ipynb
   "version": "3.10.4"
=======
   "version": "3.9.15"
>>>>>>> df30bbe8cae2c3ac9663ae2c79f0323cc8a4adb9:VQC_first_draft.ipynb
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
