{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b1b1e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch.autograd import Variable\n",
    "import pennylane as qml\n",
    "import math \n",
    "from sympy import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6092228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.5707963267948966, 1.5707963267948966]\n",
      "[1.8772398352612223, 1.923456466274096]\n",
      "[0.9129244620159346, 1.5029306837044287]\n",
      "[2.1880045929481837, 0.9954613564342298]\n",
      "[1.428292654390687, 2.5168655402409255]\n",
      "[1.0784514139262247, 0.5675029669579127]\n",
      "[2.6855123413096815, 2.1507310688234167]\n",
      "[0.5429885401462826, 2.6072121937920865]\n",
      "[1.9163689856366029, 0.16861355694868221]\n",
      "[1.9617037803765562, 3.0846360071570804]\n",
      "[0.44063989142928317, 6.159471808486976]\n",
      "[2.7999185039743866, 5.792493445015743]\n",
      "[1.0658798321901566, 3.4469961691365496]\n",
      "[1.3698304536524626, 5.897722417211437]\n",
      "[2.375266480698212, 3.893510836299411]\n",
      "[0.6290208023981475, 4.533338241557743]\n",
      "[2.0600703695341984, 5.396222854656704]\n",
      "[1.5961592835271339, 4.051957611441728]\n",
      "[1.2503204145667102, 5.052445971355824]\n",
      "[1.5707963267948966, 4.71238898038469]\n",
      "[[1.5707963267948966, 1.5707963267948966], [1.8772398352612223, 1.923456466274096], [0.9129244620159346, 1.5029306837044287], [2.1880045929481837, 0.9954613564342298], [1.428292654390687, 2.5168655402409255], [1.0784514139262247, 0.5675029669579127], [2.6855123413096815, 2.1507310688234167], [0.5429885401462826, 2.6072121937920865], [1.9163689856366029, 0.16861355694868221], [1.9617037803765562, 3.0846360071570804], [0.44063989142928317, 6.159471808486976], [2.7999185039743866, 5.792493445015743], [1.0658798321901566, 3.4469961691365496], [1.3698304536524626, 5.897722417211437], [2.375266480698212, 3.893510836299411], [0.6290208023981475, 4.533338241557743], [2.0600703695341984, 5.396222854656704], [1.5961592835271339, 4.051957611441728], [1.2503204145667102, 5.052445971355824], [1.5707963267948966, 4.71238898038469]]\n"
     ]
    }
   ],
   "source": [
    "#assuming r=1,\n",
    "def cartesian_to_spherical(x, y, z):\n",
    "    theta = math.acos(z / 1)  \n",
    "    phi = math.atan2(y, x)\n",
    "    if phi < 0:\n",
    "        phi += 2*np.pi\n",
    "    return [theta, phi]\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "def fibonacci_sphere(n):\n",
    "\n",
    "    points = []\n",
    "    phi = math.pi * (math.sqrt(5.) - 1.)  # golden angle in radians\n",
    "\n",
    "    for i in range(n):\n",
    "        y = 1 - (i / float(n - 1)) * 2  # y goes from 1 to -1\n",
    "        radius = math.sqrt(1 - y * y)  # radius at y\n",
    "\n",
    "        theta = phi * i  # golden angle increment\n",
    "\n",
    "        x = math.cos(theta) * radius\n",
    "        z = math.sin(theta) * radius\n",
    "        points.append((x, y, z))\n",
    "        sph_points = [cartesian_to_spherical(x,y,z) for x,y,z in points]\n",
    "    for i in sph_points:\n",
    "        print(i)\n",
    "    return sph_points\n",
    "\n",
    "print(fibonacci_sphere(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9545599e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.cuda.DoubleTensor if torch.cuda.is_available() else torch.DoubleTensor\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "class VariationalQuantumClassifierInterface:\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_of_input,\n",
    "            num_of_output,\n",
    "            num_of_wires,\n",
    "            num_of_layers,\n",
    "            var_Q_circuit,\n",
    "            var_Q_bias,\n",
    "            qdevice):\n",
    "\n",
    "        self.var_Q_circuit = var_Q_circuit\n",
    "        self.var_Q_bias = var_Q_bias\n",
    "        self.num_of_input = num_of_input\n",
    "        self.num_of_output = num_of_output\n",
    "        self.num_of_wires = num_of_wires\n",
    "        self.num_of_layers = num_of_layers\n",
    "\n",
    "        self.qdevice = qdevice\n",
    "\n",
    "        self.dev = qml.device(self.qdevice, wires = num_of_wires)\n",
    "\n",
    "\n",
    "    def set_params(self, var_Q_circuit, var_Q_bias):\n",
    "        self.var_Q_circuit = var_Q_circuit\n",
    "        self.var_Q_bias = var_Q_bias\n",
    "\n",
    "    def init_params(self):\n",
    "        self.var_Q_circuit = Variable(torch.tensor(0.01 * np.random.randn(self.num_of_layers, self.num_of_wires, 3), device=device).type(dtype), requires_grad=True)\n",
    "        return self.var_Q_circuit\n",
    "\n",
    "    def _statepreparation(self, angles):\n",
    "\n",
    "        \"\"\"Encoding block of circuit given angles\n",
    "\n",
    "        Args:\n",
    "            a: feature vector of rad and rad_square => np.array([rad_X_0, rad_X_1, rad_square_X_0, rad_square_X_1])\n",
    "        \"\"\"\n",
    "        # num_of_input determines the number of rotation needed.\n",
    "\n",
    "        for i in range(self.num_of_input):\n",
    "            qml.RY(angles[i,0], wires=i)\n",
    "            qml.RZ(angles[i,1], wires=i)\n",
    "\n",
    "    def _layer(self, W):\n",
    "        \"\"\" Single layer of the variational classifier.\n",
    "\n",
    "        Args:\n",
    "            W (array[float]): 2-d array of variables for one layer\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Entanglement Layer\n",
    "\n",
    "        for i in range(self.num_of_wires):\n",
    "            qml.CNOT(wires=[i, (i + 1) % self.num_of_wires])\n",
    "\n",
    "        # Rotation Layer\n",
    "        for j in range(self.num_of_wires):\n",
    "            qml.Rot(W[j, 0], W[j, 1], W[j, 2], wires=j)\n",
    "\n",
    "    def circuit(self, angles):\n",
    "\n",
    "        @qml.qnode(self.dev, interface='torch')\n",
    "        def _circuit(var_Q_circuit, angles):\n",
    "            \"\"\"The circuit of the variational classifier.\"\"\"\n",
    "            self._statepreparation(angles)\n",
    "            weights = var_Q_circuit\n",
    "\n",
    "            for W in weights:\n",
    "                self._layer(W)\n",
    "\n",
    "\n",
    "            k = self.num_of_input-1\n",
    "            return [qml.expval(qml.PauliZ(k))]\n",
    "\n",
    "        return _circuit(self.var_Q_circuit, angles)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, angles):\n",
    "\n",
    "        return self.circuit(angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70245f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "vqc = VariationalQuantumClassifierInterface(\n",
    "            num_of_input =12,\n",
    "            num_of_output =1,\n",
    "            num_of_wires=12,\n",
    "            num_of_layers=2,\n",
    "            var_Q_circuit=None,\n",
    "            var_Q_bias = None,\n",
    "            qdevice = \"default.qubit\",\n",
    "            hadamard_gate = False,\n",
    "            more_entangle = False)\n",
    "\n",
    "class VQCTorch(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.q_params = nn.Parameter(0.01 * torch.randn(2, 12, 3))\n",
    "    # n = number of amino acids, in_x in range: (0,n)\n",
    "    def get_angles_atan(self, in_x, n):\n",
    "        angles = fibonacci_sphere(n)\n",
    "        return torch.stack([angles[item][0], angles[items[1]] for item in in_x])\n",
    "\n",
    "    def forward(self, batch_item):\n",
    "        vqc.var_Q_circuit = self.q_params\n",
    "        output_batch = []\n",
    "\n",
    "        for single_item in batch_item:\n",
    "            angles = self.get_angles_atan(single_item)\n",
    "\n",
    "            q_out_elem = vqc.forward(angles)\n",
    "\n",
    "            clamp = 1e-9\n",
    "            normalized_output = torch.clamp(torch.stack(q_out_elem), min=clamp)\n",
    "            output_batch.append(normalized_output)\n",
    "\n",
    "        outputs = torch.stack(output_batch).view(len(batch_item), 1) \n",
    "\n",
    "        return outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
