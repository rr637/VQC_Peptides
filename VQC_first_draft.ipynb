{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b1b1e67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sympy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpennylane\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m numpy \u001b[38;5;28;01mas\u001b[39;00m np\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m \n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msympy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader, random_split\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sympy'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch.autograd import Variable\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import math \n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PeptideDataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6092228",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assuming r=1,\n",
    "def cartesian_to_spherical(x, y, z):\n",
    "    theta = math.acos(z / 1)  \n",
    "    phi = math.atan2(y, x)\n",
    "    if phi < 0:\n",
    "        phi += 2*np.pi\n",
    "    return [theta, phi]\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def fibonacci_sphere(n):\n",
    "\n",
    "    points = []\n",
    "    phi = math.pi * (math.sqrt(5.) - 1.)  # golden angle in radians\n",
    "\n",
    "    for i in range(n):\n",
    "        y = 1 - (i / float(n - 1)) * 2  # y goes from 1 to -1\n",
    "        radius = math.sqrt(1 - y * y)  # radius at y\n",
    "\n",
    "        theta = phi * i  # golden angle increment\n",
    "\n",
    "        x = math.cos(theta) * radius\n",
    "        z = math.sin(theta) * radius\n",
    "        points.append((x, y, z))\n",
    "        sph_points = [cartesian_to_spherical(x,y,z) for x,y,z in points]\n",
    "    \n",
    "    return sph_points\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9545599e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.cuda.DoubleTensor if torch.cuda.is_available() else torch.DoubleTensor\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "class VariationalQuantumClassifierInterface:\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_of_input,\n",
    "            num_of_output,\n",
    "            num_of_wires,\n",
    "            num_of_layers,\n",
    "            var_Q_circuit,\n",
    "            var_Q_bias,\n",
    "            qdevice):\n",
    "\n",
    "        self.var_Q_circuit = var_Q_circuit\n",
    "        self.var_Q_bias = var_Q_bias\n",
    "        self.num_of_input = num_of_input\n",
    "        self.num_of_output = num_of_output\n",
    "        self.num_of_wires = num_of_wires\n",
    "        self.num_of_layers = num_of_layers\n",
    "\n",
    "        self.qdevice = qdevice\n",
    "\n",
    "        self.dev = qml.device(self.qdevice, wires = num_of_wires)\n",
    "\n",
    "\n",
    "    def set_params(self, var_Q_circuit, var_Q_bias):\n",
    "        self.var_Q_circuit = var_Q_circuit\n",
    "        self.var_Q_bias = var_Q_bias\n",
    "\n",
    "    def init_params(self):\n",
    "        self.var_Q_circuit = Variable(torch.tensor(0.01 * np.random.randn(self.num_of_layers, self.num_of_wires, 3), device=device).type(dtype), requires_grad=True)\n",
    "        return self.var_Q_circuit\n",
    "\n",
    "    def _statepreparation(self, angles):\n",
    "\n",
    "        \"\"\"Encoding block of circuit given angles\n",
    "\n",
    "        Args:\n",
    "            a: feature vector of rad and rad_square => np.array([rad_X_0, rad_X_1, rad_square_X_0, rad_square_X_1])\n",
    "        \"\"\"\n",
    "        # num_of_input determines the number of rotation needed.\n",
    "\n",
    "        for i in range(self.num_of_input):\n",
    "            qml.RY(angles[i,0], wires=i)\n",
    "            qml.RZ(angles[i,1], wires=i)\n",
    "\n",
    "    def _layer(self, W):\n",
    "        \"\"\" Single layer of the variational classifier.\n",
    "\n",
    "        Args:\n",
    "            W (array[float]): 2-d array of variables for one layer\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Entanglement Layer\n",
    "\n",
    "        for i in range(self.num_of_wires):\n",
    "            qml.CNOT(wires=[i, (i + 1) % self.num_of_wires])\n",
    "\n",
    "        # Rotation Layer\n",
    "        for j in range(self.num_of_wires):\n",
    "            qml.Rot(W[j, 0], W[j, 1], W[j, 2], wires=j)\n",
    "\n",
    "    def circuit(self, angles):\n",
    "\n",
    "        @qml.qnode(self.dev, interface='torch', diff_method = \"parameter-shift\")\n",
    "        def _circuit(var_Q_circuit, angles):\n",
    "            \"\"\"The circuit of the variational classifier.\"\"\"\n",
    "            self._statepreparation(angles)\n",
    "            weights = var_Q_circuit\n",
    "\n",
    "            for W in weights:\n",
    "                self._layer(W)\n",
    "\n",
    "\n",
    "            k = self.num_of_input-1\n",
    "            return [qml.expval(qml.PauliZ(k))]\n",
    "\n",
    "        return _circuit(self.var_Q_circuit, angles)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, angles):\n",
    "        result = ((self.circuit(angles).item()))\n",
    "        return torch.tensor(result, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70245f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "vqc = VariationalQuantumClassifierInterface(\n",
    "            num_of_input =12,\n",
    "            num_of_output =1,\n",
    "            num_of_wires=12,\n",
    "            num_of_layers=2,\n",
    "            var_Q_circuit=None,\n",
    "            var_Q_bias = None,\n",
    "            qdevice = \"default.qubit\")\n",
    "           \n",
    "fib_angles = fibonacci_sphere(18)\n",
    "         \n",
    "\n",
    "class VQCTorch(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.q_params = nn.Parameter(0.01 * torch.randn(2, 12, 3))\n",
    "    def get_angles(self, in_x):\n",
    "        in_x_int = [int(item) for item in in_x.tolist()]\n",
    "        angles = []\n",
    "        for item in in_x_int:\n",
    "            theta = fib_angles[item][0]\n",
    "            phi = fib_angles[item][1]\n",
    "            angles.append([theta, phi])\n",
    "\n",
    "        return torch.tensor(angles, requires_grad=True)\n",
    "\n",
    "\n",
    "    def forward(self, batch_item):\n",
    "        vqc.var_Q_circuit = self.q_params\n",
    "        output_batch = []\n",
    "\n",
    "        for single_item in batch_item:\n",
    "            angles = self.get_angles(single_item)\n",
    "\n",
    "            q_out_elem = vqc.forward(angles)\n",
    "            \n",
    "            output_batch.append(q_out_elem)\n",
    "\n",
    "        outputs = torch.stack(output_batch).view(len(batch_item), 1) \n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "932c3723",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size' : 4, 'lr': 0.01, 'epochs': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "483e9cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 441978\n",
      "(Train,Test): (353582, 88396)\n"
     ]
    }
   ],
   "source": [
    " \n",
    "dataset = PeptideDataset()\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size  = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "print(f\"Dataset: {len(dataset)}\")\n",
    "print(f\"(Train,Test): {train_size,test_size}\")\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size = params['batch_size'], shuffle = True, num_workers = 2)\n",
    "train_iter = iter(train_loader)\n",
    "train_data = next(train_iter)\n",
    "x_train, y_train = train_data\n",
    "\n",
    "test_loader = DataLoader(dataset = train_dataset, batch_size = params['batch_size'], shuffle = True, num_workers = 2)\n",
    "test_iter = iter(test_loader)\n",
    "test_data = next(test_iter)\n",
    "x_test, y_test = test_data\n",
    "\n",
    "\n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50f6543e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0\n",
      "Inputs torch.Size([4, 12]) | Labels torch.Size([4, 1])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'item'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInputs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Labels \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m y_predicted \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(y_predicted, target)\n\u001b[1;32m     20\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[17], line 36\u001b[0m, in \u001b[0;36mVQCTorch.forward\u001b[0;34m(self, batch_item)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m single_item \u001b[38;5;129;01min\u001b[39;00m batch_item:\n\u001b[1;32m     34\u001b[0m     angles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_angles(single_item)\n\u001b[0;32m---> 36\u001b[0m     q_out_elem \u001b[38;5;241m=\u001b[39m \u001b[43mvqc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mangles\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     output_batch\u001b[38;5;241m.\u001b[39mappend(q_out_elem)\n\u001b[1;32m     40\u001b[0m outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(output_batch)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;28mlen\u001b[39m(batch_item), \u001b[38;5;241m1\u001b[39m) \n",
      "Cell \u001b[0;32mIn[12], line 85\u001b[0m, in \u001b[0;36mVariationalQuantumClassifierInterface.forward\u001b[0;34m(self, angles)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, angles):\n\u001b[0;32m---> 85\u001b[0m     result \u001b[38;5;241m=\u001b[39m ((\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcircuit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mangles\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m()))\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(result, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'item'"
     ]
    }
   ],
   "source": [
    "model = VQCTorch()\n",
    "\n",
    "lr = params['lr']\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)  \n",
    "\n",
    "batch_size = params['batch_size']\n",
    "num_epochs = params['epochs']\n",
    "total_samples = len(train_dataset)\n",
    "n_iterations = math.ceil(total_samples/batch_size)\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"EPOCH: {epoch}\")\n",
    "    for i, (data, target) in enumerate(train_loader):\n",
    "        if i == 0:\n",
    "            print(f'Inputs {data.shape} | Labels {target.shape}')\n",
    "        y_predicted = model(data)\n",
    "        loss = criterion(y_predicted, target)\n",
    "    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #\n",
    "        if (i+1) % 5 == 0:\n",
    "            print(f'Epoch: {epoch+1}/{num_epochs}, Step {i+1}/{n_iterations}|loss = {loss.item():.4f}')\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492be67f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-1.13.1",
   "language": "python",
   "name": "pytorch-1.13.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
